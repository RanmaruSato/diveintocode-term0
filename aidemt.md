階層的クラスタリング
近いものを順番に結合して、重心をとる
これを繰り返して最後は樹形図で表現する。
この繰り返しの過程が階層的構造になっている

非階層クラスタリング
階層的な構造を持たずあらかじめ決めた数の塊にサンプルを分類する。
サンプル数が大きいビッグデータを分析する時に適している
あらかじめいくつ分けるかは分析者が決める必要があり、公式はない
k-means
クラスターの平均(means)を使い、あらかじめクラスター数をk個に分類する
k-meansのアルゴリズムは複数ある。
Lloydだと

クラスターの核となるk個をサンプルをk個選ぶ

全てのサンプルとk個の核の距離を測る

各サンプルをもっとも近い核と同じクラスターに分割する
(この時点で全てのサンプルがk種類に分けられた

k個のクラスターの重心を求め、それを新たな核とする
（重心の位置が移動）

k-meansの短所としては初期値依存性があり、初期値が異なるだけで、結果が大きく違うことが分かります。
従って、よいクラスターを得るためには、初期値を変えて何回か分析を実施し、平均クラスター内距離が最小になる初期値を選択するなど、最適初期値での結果を採用することが望ましいといえる。

データの分散の等しいn個クラスターに分けることができる
各クラスターに分けることができる手法。
各クラスター毎にデータ重心に当たる平均値uが割り当てられる。
この重心をセントロイドと呼ぶ
分散の等しいクラスターに分けるにはSSEを使う。
SSEは各クラスターに含まれるデータ点とセントロイドとの２乗和を求めたもの（分散）。
k-meansはSSEを全クラスターで等しくかつ最小にするようにセントロイドを選ぶ


KMeansのtol init(random)
