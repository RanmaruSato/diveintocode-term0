# 微分の概要についてまとめよ（理解を採点者に伝える  

# 微分の概要について素人にも分かるように簡潔に説明せよ  
# 偏微分の概要についてまとめよ（理解を採点者に伝える)  
# 偏微分の概要について素人にも分かるように簡潔に説明せよ  
# 微分/偏微分の機械学習、深層学習における使用についてまとめよ（理解を採点者に伝える）
微分は関数の接線の傾きを算出する方法である。
ある点の傾きがわかると、それを手がかりに最小の点を探すことができる。接線の傾きの符号によって
関数の最小の位置を把握することができる。つまり、接戦の傾きは関数の増加・減少の仕方を表す。
接戦の傾きが右肩上がりであれば、その関数はその点で増加していることを表す。
勾配降下法は接戦の傾きを手がかりに計算していく方法である。
微分を理解するためには、まず平均変化率という概念を理解する必要がある。
平均変化率とは2点を結んだ直線の傾きである。
y = f(x)とした時に、f(a+h)-f(a)/h (xの増加量/yの増加量)で傾きが求められる。
ここで極限の概念から、hを限りなくaに近づけることで、2点の直線は接線に近づいていく。
したがってhを０に近づけると、接戦の傾き(微分係数)f'(x)を得ることができる。f'(a) = lim h→0 (f(a+b)-(f(a))/h
xに値を入れるとその点での接戦の傾きを返す関数である定数aを変数xに置き換えたものを導関数と呼ぶ。
このようにf(x)の導関数を求めることを微分するという

合成関数の微分は、ディープラーニングで最重要の内容である。
以下ではライプニッツの記法のように,何で微分しているかを明確に示すようにする。
f(x) = (x^2+2x+5)^10
t = x^2 + 2x +5のようにかたまりをtと置くと
与式　= t^10 ,t=x^2+2x+5
fはまずtの関数となり、tはxの関数という関係となっている。
つまり合成関数の微分とはfがtの関数,tがxの関数であるとき
df/dx = df/dt*dt/dxとなる
元を辿ればfはxの関数なのだから原理的にはxで微分できるはず。
合成関数の微分から導かれること、ひとかたまりがax+bの形の場合に限り
df(ax+b)/dx = af'(ax+b)

高階微分
2階微分の意味は関数の凹凸を表し、二回微分　> 0の場合は下に凸
=0の場合は変曲点
<0の場合は関数が上に凸だとわかる。
１回微分は関数の増減を把握して、２回微分によって増減の詳細を得ることができる。

極大極小とは周囲のどの点よりも大きい(小さい)点のことで極大or極小ならば　df(x)/dx=0
極大か極小かの判断は、２階微分を計算して結果が>0の時極小、<0の時極大


積の微分　= 微分そのまま、そのまま微分
商の微分　= (微分微分しない-微分しない微分)/{g(x)}^2


偏微分
X^2+y^2のように２つ以上の変数をもつ関数を多変数関数という。
f(x,y)をxで偏微分する場合はx以外の文字を全て定数ちとみなす。
xによる１階偏導関数と呼ぶ。
偏微分も高階微分を考えられる
シュワルツの定理
よほどのことがない限り成田つ

合成関数の微分（多変数)
fがx,yの関数、x,yがtの関数である時
 ∂f/∂t = ∂f/∂x*∂x/∂t + ∂f/∂y*∂y/∂t


f(t) = (1+t)^5(2t-1)^3
x=(1+t)^5
y=(2t-1)^3とおく

# 微分/偏微分の機械学習、深層学習における使用について素人にも分かるように簡潔に説明せよ  

合成関数の微分
合成関数の偏微分偏導関数 を求めよ。
xを入力し、xに定数wがかけられ,uとして出力される。
uが関数fの引数となり,fにより変換される（これをyとする)
出力yは元を辿れば,xの関数と考えることができる。

#極限
f(x) = x/1
x=０の時、定義されない（y軸に漸近)
つまりこれを表現するためにlim x →+0   のとき　+無限大

#平均変化率
2点を結んだ直線の傾き

# ネイピア数　= 2.718
ネイピア数f'(x)=1となるよう、指数関数の低となる
y' = (e^x)`=e^x となりe^xは微分の影響を受けない関数である。→微分が簡単になる
